--- a/src/llamafactory/train/sft/trainer.py
+++ b/src/llamafactory/train/sft/trainer.py
@@ -58,6 +58,9 @@ class CustomSeq2SeqTrainer(Seq2SeqTrainer):
     ) -> None:
         # Configure FP8 environment if enabled
         if model_args is not None and model_args.fp8:
             configure_fp8_environment(model_args)
+            
+        # Store model_args for later use
+        self.model_args = model_args
+            
         if is_transformers_version_greater_than("4.46"):
             kwargs["processing_class"] = kwargs.pop("tokenizer")
         else:
